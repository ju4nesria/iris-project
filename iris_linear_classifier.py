"""
================================================================================
CLASIFICACI√ìN DEL DATASET IRIS USANDO REGRESI√ìN LINEAL
================================================================================

Este script implementa un clasificador completo para el dataset de Iris utilizando
√∫nicamente regresi√≥n lineal con estrategia One-vs-Rest.

AUTOR: AI Assistant
FECHA: 2025
DESCRIPCI√ìN: Clasificaci√≥n multi-clase usando regresi√≥n lineal para 3 especies de iris
================================================================================
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de matplotlib para mejor visualizaci√≥n
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 12

class IrisLinearClassifier:
    """
    ================================================================================
    CLASIFICADOR DE REGRESI√ìN LINEAL PARA EL DATASET IRIS
    ================================================================================
    
    Esta clase implementa un clasificador multi-clase usando regresi√≥n lineal
    con estrategia One-vs-Rest para las tres especies de iris:
    - Iris-setosa
    - Iris-versicolor  
    - Iris-virginica
    
    M√âTODO:
    1. Entrena 3 modelos de regresi√≥n lineal (uno por cada clase)
    2. Cada modelo predice la probabilidad de pertenecer a su clase espec√≠fica
    3. La clase final se determina por la probabilidad m√°s alta
    
    CARACTER√çSTICAS:
    - Preprocesamiento autom√°tico de datos
    - Estandarizaci√≥n de caracter√≠sticas
    - Evaluaci√≥n completa con m√©tricas
    - Visualizaciones detalladas
    - Documentaci√≥n exhaustiva
    """
    
    def __init__(self, use_regularization=False, alpha=1.0):
        """
        ================================================================================
        INICIALIZAR EL CLASIFICADOR
        ================================================================================
        
        PAR√ÅMETROS:
        -----------
        use_regularization : bool, default=False
            Si usar regresi√≥n Ridge (regularizada) en lugar de regresi√≥n lineal est√°ndar
        alpha : float, default=1.0
            Par√°metro de regularizaci√≥n para Ridge (solo si use_regularization=True)
            
        ATRIBUTOS:
        ----------
        scaler : StandardScaler
            Estandarizador para normalizar las caracter√≠sticas
        label_encoder : LabelEncoder
            Codificador para convertir etiquetas de texto a n√∫meros
        models : dict
            Diccionario que almacena los modelos entrenados para cada clase
        class_names : list
            Nombres de las tres clases de iris
        feature_names : list
            Nombres de las cuatro caracter√≠sticas del dataset
        """
        print("üîß Inicializando clasificador de regresi√≥n lineal...")
        
        # Inicializar componentes de preprocesamiento
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        
        # Configuraci√≥n del modelo
        self.use_regularization = use_regularization
        self.alpha = alpha
        
        # Nombres de clases y caracter√≠sticas
        self.class_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']
        self.feature_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
        
        # Almacenar modelos entrenados
        self.models = {}
        
        print(f"‚úÖ Clasificador inicializado - Regularizaci√≥n: {use_regularization}")
    
    def load_data(self, file_path='iris.data'):
        """
        ================================================================================
        CARGAR Y PREPARAR EL DATASET IRIS
        ================================================================================
        
        Esta funci√≥n carga el dataset de iris desde un archivo CSV y lo prepara
        para el entrenamiento del modelo.
        
        PAR√ÅMETROS:
        -----------
        file_path : str, default='iris.data'
            Ruta al archivo de datos del dataset iris
            
        RETORNA:
        --------
        X : numpy.ndarray
            Matriz de caracter√≠sticas (150, 4) con las medidas de las flores
        y : numpy.ndarray
            Vector de etiquetas (150,) con las especies de iris
            
        INFORMACI√ìN DEL DATASET:
        ------------------------
        - 150 muestras totales (50 por cada clase)
        - 4 caracter√≠sticas: longitud y ancho del s√©palo y p√©talo
        - 3 clases: setosa, versicolor, virginica
        - Sin valores faltantes
        """
        print(f"üìÅ Cargando datos desde: {file_path}")
        
        try:
            # Leer el archivo CSV
            data = pd.read_csv(file_path, header=None)
            
            # Asignar nombres a las columnas
            data.columns = self.feature_names + ['species']
            
            # Eliminar filas vac√≠as si las hay
            data = data.dropna()
            
            # Separar caracter√≠sticas (X) y etiquetas (y)
            X = data[self.feature_names].values
            y = data['species'].values
            
            # Mostrar informaci√≥n del dataset
            print(f"‚úÖ Dataset cargado exitosamente")
            print(f"   üìä Forma del dataset: {X.shape}")
            print(f"   üè∑Ô∏è  Clases encontradas: {np.unique(y)}")
            print(f"   üìà Distribuci√≥n de clases: {np.bincount(self.label_encoder.fit_transform(y))}")
            
            return X, y
            
        except FileNotFoundError:
            print(f"‚ùå Error: No se pudo encontrar el archivo {file_path}")
            raise
        except Exception as e:
            print(f"‚ùå Error al cargar los datos: {str(e)}")
            raise
    
    def preprocess_data(self, X, y):
        """
        ================================================================================
        PREPROCESAR LOS DATOS PARA EL ENTRENAMIENTO
        ================================================================================
        
        Esta funci√≥n prepara los datos para el entrenamiento del modelo:
        1. Estandariza las caracter√≠sticas (media=0, desviaci√≥n=1)
        2. Codifica las etiquetas de texto a n√∫meros
        
        PAR√ÅMETROS:
        -----------
        X : numpy.ndarray
            Matriz de caracter√≠sticas originales
        y : numpy.ndarray
            Vector de etiquetas originales (texto)
            
        RETORNA:
        --------
        X_scaled : numpy.ndarray
            Caracter√≠sticas estandarizadas
        y_encoded : numpy.ndarray
            Etiquetas codificadas num√©ricamente
            
        IMPORTANCIA DE LA ESTANDARIZACI√ìN:
        ----------------------------------
        Las caracter√≠sticas tienen diferentes escalas:
        - S√©palo: 4.3-7.9 cm
        - P√©talo: 1.0-6.9 cm
        La estandarizaci√≥n evita que caracter√≠sticas con valores m√°s grandes
        dominen el modelo.
        """
        print("üîß Preprocesando datos...")
        
        # Estandarizar caracter√≠sticas (media=0, desviaci√≥n=1)
        X_scaled = self.scaler.fit_transform(X)
        
        # Codificar etiquetas de texto a n√∫meros
        y_encoded = self.label_encoder.fit_transform(y)
        
        # Mostrar estad√≠sticas de preprocesamiento
        print("‚úÖ Preprocesamiento completado")
        print(f"   üìä Caracter√≠sticas estandarizadas - Media: {X_scaled.mean():.3f}, Desv: {X_scaled.std():.3f}")
        print(f"   üè∑Ô∏è  Etiquetas codificadas: {np.unique(y_encoded)}")
        
        return X_scaled, y_encoded
    
    def train_models(self, X, y):
        """
        ================================================================================
        ENTRENAR MODELOS DE REGRESI√ìN LINEAL
        ================================================================================
        
        Esta funci√≥n entrena un modelo de regresi√≥n lineal separado para cada clase
        usando la estrategia One-vs-Rest (Uno contra Todos).
        
        ESTRATEGIA ONE-VS-REST:
        ----------------------
        Para cada clase i:
        1. Crear etiquetas binarias: 1 si pertenece a la clase i, 0 si no
        2. Entrenar un modelo de regresi√≥n lineal para predecir estas etiquetas
        3. El modelo aprende a distinguir la clase i del resto
        
        PAR√ÅMETROS:
        -----------
        X : numpy.ndarray
            Caracter√≠sticas estandarizadas de entrenamiento
        y : numpy.ndarray
            Etiquetas codificadas de entrenamiento
            
        MODELOS ENTRENADOS:
        -------------------
        - Modelo 0: Distingue Iris-setosa del resto
        - Modelo 1: Distingue Iris-versicolor del resto  
        - Modelo 2: Distingue Iris-virginica del resto
        """
        print("üöÄ Entrenando modelos de regresi√≥n lineal...")
        print("   üìã Estrategia: One-vs-Rest (Uno contra Todos)")
        
        for i, class_name in enumerate(self.class_names):
            print(f"\n   üîÑ Entrenando modelo para {class_name}...")
            
            # Crear etiquetas binarias para esta clase
            y_binary = (y == i).astype(int)
            
            # Seleccionar tipo de modelo
            if self.use_regularization:
                model = Ridge(alpha=self.alpha)
                print(f"      üìê Usando regresi√≥n Ridge (Œ±={self.alpha})")
            else:
                model = LinearRegression()
                print(f"      üìê Usando regresi√≥n lineal est√°ndar")
            
            # Entrenar el modelo
            model.fit(X, y_binary)
            
            # Calcular y mostrar R¬≤ score
            r2_score = model.score(X, y_binary)
            print(f"      ‚úÖ Modelo entrenado - R¬≤ Score: {r2_score:.4f}")
            
            # Almacenar el modelo
            self.models[class_name] = model
        
        print(f"\n‚úÖ Todos los modelos entrenados exitosamente")
        print(f"   üìä Total de modelos: {len(self.models)}")
    
    def predict(self, X):
        """
        ================================================================================
        REALIZAR PREDICCIONES CON LOS MODELOS ENTRENADOS
        ================================================================================
        
        Esta funci√≥n utiliza los modelos entrenados para predecir la clase
        de nuevas muestras de iris.
        
        PROCESO DE PREDICCI√ìN:
        ----------------------
        1. Estandarizar las caracter√≠sticas de entrada
        2. Obtener puntuaci√≥n de cada modelo (probabilidad de pertenecer a cada clase)
        3. Aplicar softmax para convertir puntuaciones en probabilidades
        4. Seleccionar la clase con mayor probabilidad
        
        PAR√ÅMETROS:
        -----------
        X : numpy.ndarray
            Caracter√≠sticas a predecir (pueden ser m√∫ltiples muestras)
            
        RETORNA:
        --------
        predictions : numpy.ndarray
            Clases predichas (0, 1, o 2)
        probabilities : numpy.ndarray
            Matriz de probabilidades para cada clase
        """
        # Estandarizar las caracter√≠sticas de entrada
        X_scaled = self.scaler.transform(X)
        
        predictions = []
        probabilities = []
        
        # Para cada muestra
        for sample in X_scaled:
            class_scores = []
            
            # Obtener puntuaci√≥n de cada modelo
            for class_name in self.class_names:
                score = self.models[class_name].predict([sample])[0]
                class_scores.append(score)
            
            # Convertir puntuaciones a probabilidades usando softmax
            # Softmax: exp(xi) / sum(exp(xj)) para j=1..n
            exp_scores = np.exp(class_scores - np.max(class_scores))  # Estabilidad num√©rica
            probs = exp_scores / np.sum(exp_scores)
            
            # Predecir la clase con mayor probabilidad
            predicted_class = np.argmax(probs)
            predictions.append(predicted_class)
            probabilities.append(probs)
        
        return np.array(predictions), np.array(probabilities)
    
    def evaluate(self, X, y_true):
        """
        ================================================================================
        EVALUAR EL RENDIMIENTO DEL MODELO
        ================================================================================
        
        Esta funci√≥n eval√∫a qu√© tan bien funciona el modelo usando varias m√©tricas
        de clasificaci√≥n est√°ndar.
        
        M√âTRICAS CALCULADAS:
        --------------------
        - Accuracy: Porcentaje de predicciones correctas
        - Precision: De las predicciones positivas, cu√°ntas son correctas
        - Recall: De los casos positivos reales, cu√°ntos detect√≥ el modelo
        - F1-Score: Media arm√≥nica entre precision y recall
        - Matriz de confusi√≥n: Detalle de aciertos y errores por clase
        
        PAR√ÅMETROS:
        -----------
        X : numpy.ndarray
            Caracter√≠sticas para evaluar
        y_true : numpy.ndarray
            Etiquetas verdaderas (codificadas num√©ricamente)
            
        RETORNA:
        --------
        results : dict
            Diccionario con todas las m√©tricas de evaluaci√≥n
        """
        print("üìä Evaluando rendimiento del modelo...")
        
        # Realizar predicciones
        y_pred, y_probs = self.predict(X)
        
        # Calcular accuracy
        accuracy = accuracy_score(y_true, y_pred)
        
        # Convertir etiquetas num√©ricas a nombres para el reporte
        y_true_names = self.label_encoder.inverse_transform(y_true)
        y_pred_names = self.label_encoder.inverse_transform(y_pred)
        
        # Generar reporte de clasificaci√≥n
        report = classification_report(y_true_names, y_pred_names, 
                                    target_names=self.class_names, 
                                    output_dict=True)
        
        # Calcular matriz de confusi√≥n
        cm = confusion_matrix(y_true, y_pred)
        
        # Compilar resultados
        results = {
            'accuracy': accuracy,
            'classification_report': report,
            'confusion_matrix': cm,
            'predictions': y_pred,
            'probabilities': y_probs
        }
        
        print(f"‚úÖ Evaluaci√≥n completada - Accuracy: {accuracy:.4f}")
        
        return results
    
    def plot_confusion_matrix(self, cm, title="Matriz de Confusi√≥n"):
        """
        ================================================================================
        VISUALIZAR LA MATRIZ DE CONFUSI√ìN
        ================================================================================
        
        La matriz de confusi√≥n muestra:
        - Diagonal principal: Predicciones correctas
        - Fuera de la diagonal: Errores de clasificaci√≥n
        
        INTERPRETACI√ìN:
        ---------------
        - Valores altos en la diagonal = buen rendimiento
        - Valores fuera de la diagonal = confusiones entre clases
        """
        plt.figure(figsize=(10, 8))
        
        # Crear heatmap de la matriz de confusi√≥n
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=self.class_names, 
                   yticklabels=self.class_names,
                   cbar_kws={'label': 'N√∫mero de muestras'})
        
        plt.title(f'{title}\n', fontsize=16, fontweight='bold')
        plt.xlabel('Clase Predicha', fontsize=14)
        plt.ylabel('Clase Real', fontsize=14)
        
        # A√±adir texto explicativo
        plt.figtext(0.5, 0.02, 
                   'Diagonal principal: Predicciones correctas\nFuera de diagonal: Errores de clasificaci√≥n', 
                   ha='center', fontsize=10, style='italic')
        
        plt.tight_layout()
        plt.show()
    
    def plot_feature_importance(self):
        """
        ================================================================================
        VISUALIZAR LA IMPORTANCIA DE LAS CARACTER√çSTICAS
        ================================================================================
        
        Muestra los coeficientes de cada modelo para entender qu√© caracter√≠sticas
        son m√°s importantes para distinguir cada clase.
        
        INTERPRETACI√ìN:
        ---------------
        - Coeficientes positivos: La caracter√≠stica aumenta la probabilidad de la clase
        - Coeficientes negativos: La caracter√≠stica disminuye la probabilidad de la clase
        - Magnitud: Qu√© tan importante es la caracter√≠stica
        """
        plt.figure(figsize=(15, 5))
        
        for i, class_name in enumerate(self.class_names):
            plt.subplot(1, 3, i+1)
            
            # Obtener coeficientes del modelo
            coefficients = self.models[class_name].coef_
            
            # Crear gr√°fico de barras
            bars = plt.bar(self.feature_names, coefficients, 
                          color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])
            
            # Personalizar gr√°fico
            plt.title(f'Importancia de Caracter√≠sticas\n{class_name}', 
                     fontsize=12, fontweight='bold')
            plt.xlabel('Caracter√≠sticas', fontsize=10)
            plt.ylabel('Valor del Coeficiente', fontsize=10)
            plt.xticks(rotation=45)
            plt.grid(axis='y', alpha=0.3)
            
            # A√±adir valores en las barras
            for bar, coef in zip(bars, coefficients):
                height = bar.get_height()
                plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                        f'{coef:.3f}', ha='center', va='bottom', fontsize=9)
        
        plt.suptitle('An√°lisis de Importancia de Caracter√≠sticas por Clase', 
                    fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.show()
    
    def plot_data_distribution(self, X, y):
        """
        ================================================================================
        VISUALIZAR LA DISTRIBUCI√ìN DE LOS DATOS
        ================================================================================
        
        Crea visualizaciones que muestran:
        1. Pairplot: Relaciones entre todas las caracter√≠sticas
        2. Matriz de correlaci√≥n: Correlaciones entre caracter√≠sticas
        
        ESTAS GR√ÅFICAS AYUDAN A:
        ------------------------
        - Entender la separabilidad de las clases
        - Identificar caracter√≠sticas m√°s discriminativas
        - Detectar patrones en los datos
        """
        # Crear DataFrame para facilitar el plotting
        df = pd.DataFrame(X, columns=self.feature_names)
        df['species'] = self.label_encoder.inverse_transform(y)
        
        # 1. PAIRPLOT - Relaciones entre caracter√≠sticas
        print("üìä Generando pairplot de caracter√≠sticas...")
        plt.figure(figsize=(15, 12))
        
        # Crear pairplot personalizado
        g = sns.pairplot(df, hue='species', diag_kind='hist', 
                        palette=['#FF6B6B', '#4ECDC4', '#45B7D1'],
                        plot_kws={'alpha': 0.7, 's': 50})
        
        g.fig.suptitle('An√°lisis de Relaciones entre Caracter√≠sticas del Dataset Iris', 
                      y=1.02, fontsize=16, fontweight='bold')
        
        # Personalizar leyenda
        g._legend.set_title('Especies de Iris')
        for text in g._legend.texts:
            text.set_fontsize(12)
        
        plt.show()
        
        # 2. MATRIZ DE CORRELACI√ìN
        print("üìä Generando matriz de correlaci√≥n...")
        plt.figure(figsize=(10, 8))
        
        # Calcular matriz de correlaci√≥n
        correlation_matrix = df[self.feature_names].corr()
        
        # Crear heatmap
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', 
                   center=0, square=True, linewidths=0.5,
                   cbar_kws={"shrink": 0.8})
        
        plt.title('Matriz de Correlaci√≥n entre Caracter√≠sticas\n', 
                 fontsize=16, fontweight='bold')
        plt.xlabel('Caracter√≠sticas', fontsize=12)
        plt.ylabel('Caracter√≠sticas', fontsize=12)
        
        # A√±adir interpretaci√≥n
        plt.figtext(0.5, 0.02, 
                   'Valores cercanos a 1: Correlaci√≥n positiva fuerte\nValores cercanos a -1: Correlaci√≥n negativa fuerte\nValores cercanos a 0: Poca correlaci√≥n', 
                   ha='center', fontsize=10, style='italic')
        
        plt.tight_layout()
        plt.show()
    
    def plot_decision_boundaries_2d(self, X, y):
        """
        ================================================================================
        VISUALIZAR FRONTERAS DE DECISI√ìN (PROYECCI√ìN 2D)
        ================================================================================
        
        Muestra las fronteras de decisi√≥n del modelo usando solo las primeras
        dos caracter√≠sticas (longitud y ancho del s√©palo).
        
        IMPORTANTE:
        -----------
        Esta es una proyecci√≥n 2D de un modelo 4D. Las fronteras reales
        son m√°s complejas en el espacio completo de 4 dimensiones.
        """
        print("üìä Generando fronteras de decisi√≥n 2D...")
        
        # Usar solo las primeras dos caracter√≠sticas para visualizaci√≥n 2D
        X_2d = X[:, :2]
        
        # Crear malla de puntos para las fronteras
        h = 0.02  # Tama√±o del paso
        x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1
        y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                           np.arange(y_min, y_max, h))
        
        # Hacer predicciones en la malla
        mesh_points = np.c_[xx.ravel(), yy.ravel()]
        # Completar con ceros para las otras caracter√≠sticas
        mesh_full = np.zeros((mesh_points.shape[0], 4))
        mesh_full[:, :2] = mesh_points
        
        # Predecir clases para todos los puntos de la malla
        Z = self.predict(mesh_full)[0]
        Z = Z.reshape(xx.shape)
        
        # Crear visualizaci√≥n
        plt.figure(figsize=(12, 10))
        
        # Dibujar fronteras de decisi√≥n
        plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdYlBu)
        
        # Dibujar puntos de datos reales
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        for i, class_name in enumerate(self.class_names):
            mask = y == i
            plt.scatter(X_2d[mask, 0], X_2d[mask, 1], 
                       c=colors[i], label=class_name, 
                       edgecolors='black', linewidth=0.5, s=60, alpha=0.8)
        
        # Personalizar gr√°fico
        plt.xlabel('Longitud del S√©palo (cm)', fontsize=12)
        plt.ylabel('Ancho del S√©palo (cm)', fontsize=12)
        plt.title('Fronteras de Decisi√≥n del Modelo\n(Proyecci√≥n 2D usando S√©palo)', 
                 fontsize=14, fontweight='bold')
        plt.legend(title='Especies de Iris', loc='upper right')
        plt.colorbar(label='Clase Predicha')
        
        # A√±adir nota explicativa
        plt.figtext(0.5, 0.02, 
                   'Nota: Esta es una proyecci√≥n 2D. El modelo real usa 4 caracter√≠sticas.\nLas fronteras reales son m√°s complejas en el espacio 4D completo.', 
                   ha='center', fontsize=10, style='italic')
        
        plt.tight_layout()
        plt.show()
    
    def print_detailed_results(self, results, dataset_name="Dataset"):
        """
        ================================================================================
        IMPRIMIR RESULTADOS DETALLADOS DE LA EVALUACI√ìN
        ================================================================================
        
        Muestra un reporte completo y detallado de todas las m√©tricas de evaluaci√≥n.
        """
        print(f"\n{'='*80}")
        print(f"RESULTADOS DETALLADOS - {dataset_name.upper()}")
        print(f"{'='*80}")
        
        # Accuracy general
        accuracy = results['accuracy']
        print(f"\nüéØ PRECISI√ìN GENERAL: {accuracy:.4f} ({accuracy*100:.2f}%)")
        
        # Reporte de clasificaci√≥n detallado
        print(f"\nüìä REPORTE DE CLASIFICACI√ìN DETALLADO:")
        print(f"{'-'*60}")
        report = results['classification_report']
        
        # M√©tricas por clase
        for class_name in self.class_names:
            if class_name in report:
                metrics = report[class_name]
                print(f"\nüå∫ {class_name.upper()}:")
                print(f"   üìà Precisi√≥n: {metrics['precision']:.4f} - De las predicciones positivas, {metrics['precision']*100:.1f}% son correctas")
                print(f"   üìà Recall:    {metrics['recall']:.4f} - De los casos reales, {metrics['recall']*100:.1f}% fueron detectados")
                print(f"   üìà F1-Score:  {metrics['f1-score']:.4f} - Media arm√≥nica entre precisi√≥n y recall")
                print(f"   üìà Soporte:   {metrics['support']:.0f} - N√∫mero de muestras de esta clase")
        
        # Promedios
        print(f"\nüìä PROMEDIOS:")
        print(f"   üìà Precisi√≥n Macro: {report['macro avg']['precision']:.4f}")
        print(f"   üìà Recall Macro:    {report['macro avg']['recall']:.4f}")
        print(f"   üìà F1-Score Macro:  {report['macro avg']['f1-score']:.4f}")
        print(f"   üìà Precisi√≥n Ponderada: {report['weighted avg']['precision']:.4f}")
        print(f"   üìà Recall Ponderado:    {report['weighted avg']['recall']:.4f}")
        print(f"   üìà F1-Score Ponderado:  {report['weighted avg']['f1-score']:.4f}")
        
        # Matriz de confusi√≥n
        print(f"\nüî¢ MATRIZ DE CONFUSI√ìN:")
        print(f"{'-'*60}")
        cm = results['confusion_matrix']
        
        # Encabezado
        print("Real\\Predicho", end="")
        for class_name in self.class_names:
            print(f"\t{class_name[:8]}", end="")
        print()
        
        # Filas de la matriz
        for i, class_name in enumerate(self.class_names):
            print(f"{class_name[:8]}", end="")
            for j in range(len(self.class_names)):
                print(f"\t\t{cm[i][j]}", end="")
            print()
        
        # Interpretaci√≥n de la matriz
        print(f"\nüí° INTERPRETACI√ìN:")
        print(f"   ‚úÖ Diagonal principal: Predicciones correctas")
        print(f"   ‚ùå Fuera de diagonal: Errores de clasificaci√≥n")
        for i in range(len(self.class_names)):
            correct = cm[i][i]
            total = cm[i].sum()
            print(f"   üìä {self.class_names[i]}: {correct}/{total} correctas ({correct/total*100:.1f}%)")


def main():
    """
    ================================================================================
    FUNCI√ìN PRINCIPAL - EJECUTAR CLASIFICACI√ìN COMPLETA
    ================================================================================
    
    Esta funci√≥n ejecuta todo el pipeline de clasificaci√≥n:
    1. Cargar datos
    2. Preprocesar
    3. Dividir en entrenamiento y prueba
    4. Entrenar modelos
    5. Evaluar rendimiento
    6. Generar visualizaciones
    7. Mostrar resultados detallados
    """
    print("="*80)
    print("üå∫ CLASIFICACI√ìN DEL DATASET IRIS USANDO REGRESI√ìN LINEAL üå∫")
    print("="*80)
    print("üìã Este programa clasifica flores de iris en 3 especies usando regresi√≥n lineal")
    print("üî¨ M√©todo: One-vs-Rest con regresi√≥n lineal est√°ndar")
    print("="*80)
    
    # ================================================================================
    # 1. INICIALIZAR CLASIFICADOR
    # ================================================================================
    print("\nüöÄ PASO 1: INICIALIZANDO CLASIFICADOR")
    print("-" * 50)
    classifier = IrisLinearClassifier(use_regularization=False)
    
    # ================================================================================
    # 2. CARGAR Y PREPROCESAR DATOS
    # ================================================================================
    print("\nüöÄ PASO 2: CARGANDO Y PREPROCESANDO DATOS")
    print("-" * 50)
    X, y = classifier.load_data('iris.data')
    X_scaled, y_encoded = classifier.preprocess_data(X, y)
    
    # ================================================================================
    # 3. DIVIDIR DATOS EN ENTRENAMIENTO Y PRUEBA
    # ================================================================================
    print("\nüöÄ PASO 3: DIVIDIENDO DATOS EN ENTRENAMIENTO Y PRUEBA")
    print("-" * 50)
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded
    )
    
    print(f"‚úÖ Divisi√≥n completada:")
    print(f"   üìä Conjunto de entrenamiento: {X_train.shape[0]} muestras")
    print(f"   üìä Conjunto de prueba: {X_test.shape[0]} muestras")
    print(f"   üìä Caracter√≠sticas: {X_train.shape[1]}")
    
    # ================================================================================
    # 4. ENTRENAR MODELOS
    # ================================================================================
    print("\nüöÄ PASO 4: ENTRENANDO MODELOS DE REGRESI√ìN LINEAL")
    print("-" * 50)
    classifier.train_models(X_train, y_train)
    
    # ================================================================================
    # 5. EVALUAR RENDIMIENTO
    # ================================================================================
    print("\nüöÄ PASO 5: EVALUANDO RENDIMIENTO DEL MODELO")
    print("-" * 50)
    
    # Evaluar en conjunto de entrenamiento
    print("\nüìä EVALUACI√ìN EN CONJUNTO DE ENTRENAMIENTO:")
    train_results = classifier.evaluate(X_train, y_train)
    classifier.print_detailed_results(train_results, "Entrenamiento")
    
    # Evaluar en conjunto de prueba
    print("\nüìä EVALUACI√ìN EN CONJUNTO DE PRUEBA:")
    test_results = classifier.evaluate(X_test, y_test)
    classifier.print_detailed_results(test_results, "Prueba")
    
    # ================================================================================
    # 6. GENERAR VISUALIZACIONES
    # ================================================================================
    print("\nüöÄ PASO 6: GENERANDO VISUALIZACIONES")
    print("-" * 50)
    print("üìä Generando gr√°ficas de an√°lisis...")
    
    # Distribuci√≥n de datos
    classifier.plot_data_distribution(X, y_encoded)
    
    # Matrices de confusi√≥n
    classifier.plot_confusion_matrix(train_results['confusion_matrix'], 
                                   "Matriz de Confusi√≥n - Entrenamiento")
    classifier.plot_confusion_matrix(test_results['confusion_matrix'], 
                                   "Matriz de Confusi√≥n - Prueba")
    
    # Importancia de caracter√≠sticas
    classifier.plot_feature_importance()
    
    # Fronteras de decisi√≥n
    classifier.plot_decision_boundaries_2d(X, y_encoded)
    
    # ================================================================================
    # 7. RESUMEN FINAL
    # ================================================================================
    print("\n" + "="*80)
    print("üìã RESUMEN FINAL DEL EXPERIMENTO")
    print("="*80)
    
    train_accuracy = train_results['accuracy']
    test_accuracy = test_results['accuracy']
    overfitting = train_accuracy - test_accuracy
    
    print(f"\nüéØ RESULTADOS PRINCIPALES:")
    print(f"   üìà Precisi√≥n de Entrenamiento: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)")
    print(f"   üìà Precisi√≥n de Prueba: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    print(f"   üìà Sobreajuste: {overfitting:.4f} ({overfitting*100:.2f}%)")
    
    print(f"\nüîç AN√ÅLISIS DE RENDIMIENTO:")
    if overfitting > 0.1:
        print(f"   ‚ö†Ô∏è  El modelo muestra sobreajuste significativo")
    elif overfitting < -0.05:
        print(f"   ‚ö†Ô∏è  El modelo podr√≠a estar subajustado")
    else:
        print(f"   ‚úÖ El modelo tiene un balance adecuado entre entrenamiento y prueba")
    
    print(f"\nüí° CONCLUSIONES:")
    print(f"   üå∫ Iris-setosa: F√°cilmente separable (linealmente separable)")
    print(f"   üå∫ Iris-versicolor y virginica: M√°s dif√≠ciles de separar")
    print(f"   üìä La regresi√≥n lineal funciona razonablemente bien para este problema")
    print(f"   üî¨ Para mejores resultados, considerar regresi√≥n log√≠stica o SVM")
    
    print(f"\n‚úÖ EXPERIMENTO COMPLETADO EXITOSAMENTE")
    print("="*80)
    
    return classifier, train_results, test_results


if __name__ == "__main__":
    # Ejecutar el experimento completo
    classifier, train_results, test_results = main()
